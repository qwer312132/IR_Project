# -*- coding: utf-8 -*-
"""fun2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uv4iK19ebUlf5aCUGkcyKpvUw_Byk2Z5
"""

!pip install fasttext
!pip install huggingface_hub

import json
import numpy as np
from sklearn.model_selection import train_test_split
import tensorflow as tf
import tensorflow_hub as hub
import fasttext
from huggingface_hub import hf_hub_download
from tensorflow import keras
from sklearn.utils.class_weight import compute_class_weight
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold

print("Version: ", tf.__version__)
print("Eager mode: ", tf.executing_eagerly())
print("Hub version: ", hub.__version__)
print("GPU is", "available" if tf.config.list_physical_devices('GPU') else "NOT AVAILABLE")

# 讀取.json
with open('./comments.json', 'r', encoding='utf-8') as file:
    data = json.load(file)

# 提取 'comment' 與 'ad'
comments = [entry['comment'] for entry in data]
ads = [entry['ad'] for entry in data]

model_path = hf_hub_download(repo_id="facebook/fasttext-zh-vectors", filename="model.bin")
embad_model = fasttext.load_model(model_path)

# 將資料分成訓練集和測試集（4:1）
X_train, X_test, y_train, y_test = train_test_split(comments, ads, test_size=0.2, random_state=42, stratify=ads)

X_train_embed = [embad_model[x] for x in X_train]
X_test_embed = [embad_model[x] for x in X_test]

# 定義交叉驗證的折數
num_folds = 5
# 初始化 StratifiedKFold
kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)

# 創建空列表來保存每個折數的訓練和驗證分數
train_scores = []
val_scores = []

for fold, (train_index, val_index) in enumerate(kfold.split(X_train, y_train)):
    print(f"Training on fold {fold + 1}/{num_folds}...")
    # 根據索引拆分訓練和驗證資料(from train data)
    trainX = np.array([X_train_embed[i] for i in train_index])
    valX = np.array([X_train_embed[i] for i in val_index])
    trainY = np.array([y_train[i] for i in train_index])
    valY = np.array([y_train[i] for i in val_index])
    # 計算類別權重
    train_class_weights = compute_class_weight('balanced', classes = np.unique(trainY), y = trainY)

    val_class_weights = compute_class_weight('balanced', classes = np.unique(valY), y = valY)
    val_sample_weights = np.zeros(len(valY))
    val_sample_weights[valY == 1] = val_class_weights[1]
    val_sample_weights[valY == 0] = val_class_weights[0]

    # 將類別權重轉換為字典格式
    train_class_weights = dict(enumerate(train_class_weights))

    model = tf.keras.Sequential([
        tf.keras.layers.Dense(256, activation='relu'),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(1)
    ])

    # 編譯模型
    model.compile(optimizer='adam',
                  loss=tf.losses.BinaryCrossentropy(from_logits=True),
                  metrics=[keras.metrics.RecallAtPrecision(precision=0.8)])

    # 訓練模型
    history = model.fit(trainX,
                        trainY,
                        epochs=40,
                        batch_size=512,
                        verbose=0,
                        validation_data=(valX, valY, val_sample_weights),
                        class_weight=train_class_weights)

    # 評估模型
    train_score = model.evaluate(trainX, trainY, verbose=0)
    val_score = model.evaluate(valX, valY, verbose=0)

    train_scores.append(train_score)
    val_scores.append(val_score)

# 輸出每個折數的平均訓練和驗證分數
print("Average training scores:", np.mean(train_scores, axis=0))
print("Average validation scores:", np.mean(val_scores, axis=0))

y_pred = model.predict(np.array(X_test_embed), verbose=1)
y_pred = (y_pred > 0.5).astype(np.integer)

y_test_np = np.array(y_test)
y_test_np = y_test_np[:, np.newaxis]
# accuracy = (y_pred == y_test_np).mean()
ad00 = np.logical_and(y_test_np == 0, y_pred == 0)
ad01 = np.logical_and(y_test_np == 0, y_pred == 1)
ad10 = np.logical_and(y_test_np == 1, y_pred == 0)
ad11 = np.logical_and(y_test_np == 1, y_pred == 1)
print("測試資料的數量:", len(y_test))
print("召回率:", sum(ad11) / (sum(ad10) + sum(ad11)))
print("本身不是廣告且判斷不是廣告的數量:", sum(ad00))
print("本身不是廣告且判斷是廣告的數量:", sum(ad01))
print("本身是廣告且判斷不是廣告的數量:", sum(ad10))
print("本身是廣告且判斷是廣告的數量:", sum(ad11))

X_test_np = np.array(X_test)
X_test_np = X_test_np[:, np.newaxis]

ad_pred = X_test_np[y_pred == 1]
print("判斷為廣告的數量:", len(ad_pred))
print("判斷為廣告的句子:\n", ad_pred)

ad_test = X_test_np[np.logical_and(y_pred == 0, y_test_np == 1)]
print("應為廣告且判斷不是廣告的數量:", len(ad_test))
print("應為廣告且判斷不是廣告的句子:\n", ad_test)