# -*- coding: utf-8 -*-
"""fun2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uv4iK19ebUlf5aCUGkcyKpvUw_Byk2Z5
"""

import json
import numpy as np
from sklearn.model_selection import train_test_split
import tensorflow as tf
import tensorflow_hub as hub
# from ckiptagger import data_utils, construct_dictionary, WS, POS, NER
# from huggingface_hub import hf_hub_download
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold

print("Version: ", tf.__version__)
print("Eager mode: ", tf.executing_eagerly())
print("Hub version: ", hub.__version__)
print("GPU is", "available" if tf.config.list_physical_devices('GPU') else "NOT AVAILABLE")

# 讀取.json
with open('./comments.json', 'r', encoding='utf-8') as file:
    data = json.load(file)

# 提取 'comment' 與 'ad'
comments = [entry['comment'] for entry in data]
ads = [entry['ad'] for entry in data]

embed_url = "https://tfhub.dev/google/nnlm-zh-dim50/2"
hub_layer = hub.KerasLayer(embed_url, input_shape=[], dtype=tf.string, trainable=True)

# 將資料分成訓練集和測試集（4:1）
X_train, X_test, y_train, y_test = train_test_split(comments, ads, test_size=0.2, random_state=42, stratify=ads)

# 定義交叉驗證的折數
num_folds = 5
# 初始化 StratifiedKFold
kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)

# 創建空列表來保存每個折數的訓練和驗證分數
train_scores = []
val_scores = []

for fold, (train_index, val_index) in enumerate(kfold.split(X_train, y_train)):
    print(f"Training on fold {fold + 1}/{num_folds}...")
    # 根據索引拆分訓練和驗證資料
    trainX = np.array([X_train[i] for i in train_index])
    valX = np.array([X_train[i] for i in val_index])
    trainY = np.array([y_train[i] for i in train_index])
    valY = np.array([y_train[i] for i in val_index])

    model = tf.keras.Sequential([
        hub_layer,
        tf.keras.layers.Dense(256, activation='relu'),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(1)
    ])

    # 編譯模型
    model.compile(optimizer='adam',
                  loss=tf.losses.BinaryCrossentropy(from_logits=True),
                  metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])

    # 訓練模型
    history = model.fit(trainX,
                        trainY,
                        epochs=40,
                        batch_size=512,
                        verbose=0)

    # 評估模型
    train_score = model.evaluate(trainX, trainY, verbose=0)
    val_score = model.evaluate(valX, valY, verbose=0)

    train_scores.append(train_score)
    val_scores.append(val_score)

# 輸出每個折數的平均訓練和驗證分數
print("Average training scores:", np.mean(train_scores, axis=0))
print("Average validation scores:", np.mean(val_scores, axis=0))

y_pred = model.predict(X_test, verbose=1)
y_pred = (y_pred > 0.5).astype(np.integer)

y_test_np = np.array(y_test)
y_test_np = y_test_np[:, np.newaxis]
accuracy = (y_pred == y_test_np).mean()
ad00 = np.logical_and(y_test_np == 0, y_pred == 0)
ad01 = np.logical_and(y_test_np == 0, y_pred == 1)
ad10 = np.logical_and(y_test_np == 1, y_pred == 0)
ad11 = np.logical_and(y_test_np == 1, y_pred == 1)
print("測試資料的數量:", len(y_test))
print("準確度:", accuracy)
print("本身不是廣告且判斷不是廣告的數量:", sum(ad00))
print("本身不是廣告且判斷是廣告的數量:", sum(ad01))
print("本身是廣告且判斷不是廣告的數量:", sum(ad10))
print("本身是廣告且判斷是廣告的數量:", sum(ad11))

X_test_np = np.array(X_test)
X_test_np = X_test_np[:, np.newaxis]

ad_pred = X_test_np[y_pred == 1]
print("判斷為廣告的數量:", len(ad_pred))
print("判斷為廣告的句子:\n", ad_pred)

ad_test = X_test_np[np.logical_and(y_pred == 0, y_test_np == 1)]
print("應為廣告卻被誤判的數量:", len(ad_test))
print("應為廣告卻被誤判的句子:\n", ad_test)